{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "edf30c9f",
      "metadata": {
        "id": "edf30c9f"
      },
      "source": [
        "Logistic Regression to predict if songs contain love"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "f64ac315",
      "metadata": {
        "id": "f64ac315"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "303c6fa0",
      "metadata": {
        "id": "303c6fa0"
      },
      "outputs": [],
      "source": [
        "#Read in datasets\n",
        "spotify_data = pd.read_csv(\"../data/spotify_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "24a8183a",
      "metadata": {
        "id": "24a8183a"
      },
      "outputs": [],
      "source": [
        "#Adding Has Love column\n",
        "song_attribute_data = spotify_data\n",
        "\n",
        "titles = song_attribute_data[\"Song\"]\n",
        "titles = titles.str.split(pat=\" \", expand=True)\n",
        "\n",
        "song_attribute_data[\"Has Word Love?\"] = song_attribute_data['Song'].str.contains(\"Love\")\n",
        "song_attribute_data_love = song_attribute_data[song_attribute_data[\"Has Word Love?\"]]\n",
        "\n",
        "song_attribute_data = song_attribute_data.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "53896a96",
      "metadata": {
        "id": "53896a96"
      },
      "outputs": [],
      "source": [
        "#Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"speechiness\", \"valence\", \"tempo\", \"time_signature\", \"Popularity Points Awarded\"]]\n",
        "\n",
        "def minmax(z):\n",
        "    z = (z-min(z))/(max(z)-min(z))\n",
        "    return z\n",
        "X = X.apply(minmax,axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "01e8114f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01e8114f",
        "outputId": "8a694a67-904a-4b4b-b6e4-3af0d5bfca2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.9174862912350944\n",
            "Test R^2 0.9136790810998956\n"
          ]
        }
      ],
      "source": [
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000).fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))\n",
        "#Pretty good accuracy scores for these predictors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "C7-bNZSHcxvx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7-bNZSHcxvx",
        "outputId": "ecc361e1-4d41-4e8f-aa4f-c6b36d2625a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.9174862912350944\n",
            "Test R^2 0.9136790810998956\n"
          ]
        }
      ],
      "source": [
        "#Run regression with all variables\n",
        "X_n = song_attribute_data.iloc[:, [8] + [9] + list(range(11, 24))]\n",
        "X_n = X_n.apply(minmax,axis=1)\n",
        "\n",
        "dummies = pd.DataFrame([])\n",
        "new_dummies = pd.get_dummies(song_attribute_data.loc[:,\"spotify_track_explicit\"], drop_first=True, dtype=int)\n",
        "dummies = pd.concat([dummies, new_dummies], axis=1, ignore_index=True)\n",
        "\n",
        "X2 = pd.concat([X_n,dummies],axis=1)\n",
        "X2.columns = X2.columns.astype(str)\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2,y, test_size=.2, random_state=100)\n",
        "\n",
        "reg2 = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000).fit(X2_train,y2_train)\n",
        "\n",
        "print(\"Training R^2\", reg2.score(X2_train, y2_train))\n",
        "print(\"Test R^2\", reg2.score(X2_test, y2_test))\n",
        "#Exact same R^2 values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8930214",
      "metadata": {},
      "source": [
        "This code chunk shows that our target variable is highly imbalanced. Almost 92% of the songs do not have the word 'love' in the title, so our model has learned to always return an accuracy close to 1, which explains why the model always gives an accuracy close to .91 no matter what features or how many features we use. \n",
        "\n",
        "Thus, below, we will add a new parameter called class_weight=\"balanced\" to tell our model to care and focus more on the underrepresented population, which in this case is True: the title has the word 'love'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "d58e8d44",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Has Word Love?\n",
            "False    0.916725\n",
            "True     0.083275\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(song_attribute_data[\"Has Word Love?\"].value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0233911",
      "metadata": {},
      "source": [
        "Let's see how the accuracy scores changed after adding this new parameter, class_weight=\"balanced\", that tells the model to focus more on the underrepresented data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "d7814d8e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.324310209765863\n",
            "Test R^2 0.33379742429516185\n"
          ]
        }
      ],
      "source": [
        "#Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"speechiness\", \"valence\", \"tempo\", \"time_signature\", \"Popularity Points Awarded\"]]\n",
        "\n",
        "X = X.apply(minmax,axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)\n",
        "\n",
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000,\n",
        "                         class_weight='balanced').fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))\n",
        "# We can see that the accuracy decreased"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34592176",
      "metadata": {},
      "source": [
        "Without adjusting:\n",
        "\n",
        "- Training R^2 0.9174862912350944\n",
        "- Test R^2 0.9136790810998956\n",
        "\n",
        "After adjusting:\n",
        "\n",
        "- Training R^2 0.324310209765863\n",
        "- Test R^2 0.33379742429516185\n",
        "\n",
        "We can see that the accuracy decreased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "0b561352",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.5130124466881365\n",
            "Test R^2 0.5144448311869126\n"
          ]
        }
      ],
      "source": [
        "#Run regression with all variables\n",
        "X_n = song_attribute_data.iloc[:, [8] + [9] + list(range(11, 24))]\n",
        "X_n = X_n.apply(minmax,axis=1)\n",
        "\n",
        "dummies = pd.DataFrame([])\n",
        "new_dummies = pd.get_dummies(song_attribute_data.loc[:,\"spotify_track_explicit\"], drop_first=True, dtype=int)\n",
        "dummies = pd.concat([dummies, new_dummies], axis=1, ignore_index=True)\n",
        "\n",
        "X2 = pd.concat([X_n,dummies],axis=1)\n",
        "X2.columns = X2.columns.astype(str)\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2,y, test_size=.2, random_state=100)\n",
        "\n",
        "reg2 = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000, \n",
        "                         class_weight='balanced'\n",
        "                         ).fit(X2_train,y2_train)\n",
        "\n",
        "print(\"Training R^2\", reg2.score(X2_train, y2_train))\n",
        "print(\"Test R^2\", reg2.score(X2_test, y2_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df964836",
      "metadata": {},
      "source": [
        "We can see that the accuracy scores are worse, but by using all the variables, the features explained more of the variance compared to cherry picking which variables to use."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7188cc8b",
      "metadata": {},
      "source": [
        "Let's try some more feature combinations using class_weight = 'balanced'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "6e55093c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.4069109583079467\n",
            "Test R^2 0.40932822833275323\n"
          ]
        }
      ],
      "source": [
        "# Do more popular songs have the word 'love'?\n",
        "#Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"Popularity Points Awarded\"]]\n",
        "\n",
        "def minmax(z):\n",
        "    z = (z-min(z))/(max(z)-min(z))\n",
        "    return z\n",
        "X = X.apply(minmax,axis=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=100)\n",
        "\n",
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000, \n",
        "                         class_weight='balanced'\n",
        "                         ).fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "6e9ed448",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.6430498737923231\n",
            "Test R^2 0.6359206404455273\n"
          ]
        }
      ],
      "source": [
        "#Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"liveness\"]]\n",
        "\n",
        "X = X.apply(minmax,axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)\n",
        "\n",
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000,\n",
        "                         class_weight='balanced').fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))\n",
        "# This is the highest accuracy so far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "2083176b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.6167638610845156\n",
            "Test R^2 0.608771319178559\n"
          ]
        }
      ],
      "source": [
        "# Trying a mix\n",
        "# Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"valence\", \"acousticness\", \"liveness\", \"instrumentalness\"]]\n",
        "\n",
        "X = X.apply(minmax,axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)\n",
        "\n",
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000,\n",
        "                         class_weight='balanced').fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
