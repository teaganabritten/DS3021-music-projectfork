{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "edf30c9f",
      "metadata": {
        "id": "edf30c9f"
      },
      "source": [
        "**Logistic Regression to predict if song titles contain love**\n",
        "\n",
        "For this project, we were interested in a songs dataset from the Spotify API. We found that love was one of the most frequent words used in song titles. For this reason, we decided that we wanted to explore what variables were associated with a song being about love, measured by it having love in the title. To ask this specifically, our question of interest was:    \n",
        "Does popularity score or valence affect if a song will be about love?    \n",
        "For this question, we decided that we wanted our output to be a prediction of the probability of a song having love in it, which would be best represented using a logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f64ac315",
      "metadata": {
        "id": "f64ac315"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "303c6fa0",
      "metadata": {
        "id": "303c6fa0"
      },
      "outputs": [],
      "source": [
        "#Read in datasets\n",
        "spotify_data = pd.read_csv(\"../data/spotify_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24a8183a",
      "metadata": {
        "id": "24a8183a"
      },
      "outputs": [],
      "source": [
        "#Adding 'Has Love' column\n",
        "song_attribute_data = spotify_data\n",
        "\n",
        "titles = song_attribute_data[\"Song\"]\n",
        "titles = titles.str.split(pat=\" \", expand=True)\n",
        "\n",
        "song_attribute_data[\"Has Word Love?\"] = song_attribute_data['Song'].str.contains(\"Love\")\n",
        "song_attribute_data_love = song_attribute_data[song_attribute_data[\"Has Word Love?\"]]\n",
        "\n",
        "song_attribute_data = song_attribute_data.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53896a96",
      "metadata": {
        "id": "53896a96"
      },
      "outputs": [],
      "source": [
        "#Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"speechiness\", \"valence\", \"tempo\", \"time_signature\", \"Popularity Points Awarded\"]]\n",
        "\n",
        "def minmax(z):\n",
        "    z = (z-min(z))/(max(z)-min(z))\n",
        "    return z\n",
        "X = X.apply(minmax,axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e8114f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01e8114f",
        "outputId": "8a694a67-904a-4b4b-b6e4-3af0d5bfca2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.9174862912350944\n",
            "Test R^2 0.9136790810998956\n"
          ]
        }
      ],
      "source": [
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000).fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))\n",
        "#Pretty good accuracy scores for these predictors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C7-bNZSHcxvx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7-bNZSHcxvx",
        "outputId": "ecc361e1-4d41-4e8f-aa4f-c6b36d2625a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.9174862912350944\n",
            "Test R^2 0.9136790810998956\n"
          ]
        }
      ],
      "source": [
        "#Run regression with all variables\n",
        "X_n = song_attribute_data.iloc[:, [8] + [9] + list(range(11, 24))]\n",
        "X_n = X_n.apply(minmax,axis=1)\n",
        "\n",
        "dummies = pd.DataFrame([])\n",
        "new_dummies = pd.get_dummies(song_attribute_data.loc[:,\"spotify_track_explicit\"], drop_first=True, dtype=int)\n",
        "dummies = pd.concat([dummies, new_dummies], axis=1, ignore_index=True)\n",
        "\n",
        "X2 = pd.concat([X_n,dummies],axis=1)\n",
        "X2.columns = X2.columns.astype(str)\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2,y, test_size=.2, random_state=100)\n",
        "\n",
        "reg2 = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000).fit(X2_train,y2_train)\n",
        "\n",
        "print(\"Training R^2\", reg2.score(X2_train, y2_train))\n",
        "print(\"Test R^2\", reg2.score(X2_test, y2_test))\n",
        "#Exact same R^2 values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8930214",
      "metadata": {
        "id": "e8930214"
      },
      "source": [
        "This code chunk shows that our target variable is highly imbalanced. Almost 92% of the songs do not have the word 'love' in the title, so our model has learned to always return an accuracy close to 1, which explains why the model always gives an accuracy close to .91 no matter what features or how many features we use.\n",
        "\n",
        "Thus, below, we will add a new parameter called class_weight=\"balanced\" to tell our model to care and focus more on the underrepresented population, which in this case is True: the title has the word 'love'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d58e8d44",
      "metadata": {
        "id": "d58e8d44",
        "outputId": "499cfa77-8e86-43b5-fa06-9842e570d7f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Has Word Love?\n",
            "False    0.916725\n",
            "True     0.083275\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(song_attribute_data[\"Has Word Love?\"].value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0233911",
      "metadata": {
        "id": "c0233911"
      },
      "source": [
        "Let's see how the accuracy scores changed after adding this new parameter, class_weight=\"balanced\", that tells the model to focus more on the underrepresented data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7814d8e",
      "metadata": {
        "id": "d7814d8e",
        "outputId": "2fa2160c-4ef4-451e-cee6-33054aefec80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.324310209765863\n",
            "Test R^2 0.33379742429516185\n"
          ]
        }
      ],
      "source": [
        "#Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"speechiness\", \"valence\", \"tempo\", \"time_signature\", \"Popularity Points Awarded\"]]\n",
        "\n",
        "X = X.apply(minmax,axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)\n",
        "\n",
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000,\n",
        "                         class_weight='balanced').fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))\n",
        "# We can see that the accuracy decreased"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34592176",
      "metadata": {
        "id": "34592176"
      },
      "source": [
        "Without adjusting:\n",
        "\n",
        "- Training R^2 0.9174862912350944\n",
        "- Test R^2 0.9136790810998956\n",
        "\n",
        "After adjusting:\n",
        "\n",
        "- Training R^2 0.324310209765863\n",
        "- Test R^2 0.33379742429516185\n",
        "\n",
        "We can see that the accuracy decreased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b561352",
      "metadata": {
        "id": "0b561352",
        "outputId": "1a78a1b1-2f46-440d-b249-819f22babf5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.5130124466881365\n",
            "Test R^2 0.5144448311869126\n"
          ]
        }
      ],
      "source": [
        "#Run regression with all variables\n",
        "X_n = song_attribute_data.iloc[:, [8] + [9] + list(range(11, 24))]\n",
        "X_n = X_n.apply(minmax,axis=1)\n",
        "\n",
        "dummies = pd.DataFrame([])\n",
        "new_dummies = pd.get_dummies(song_attribute_data.loc[:,\"spotify_track_explicit\"], drop_first=True, dtype=int)\n",
        "dummies = pd.concat([dummies, new_dummies], axis=1, ignore_index=True)\n",
        "\n",
        "X2 = pd.concat([X_n,dummies],axis=1)\n",
        "X2.columns = X2.columns.astype(str)\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2,y, test_size=.2, random_state=100)\n",
        "\n",
        "reg2 = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000,\n",
        "                         class_weight='balanced'\n",
        "                         ).fit(X2_train,y2_train)\n",
        "\n",
        "print(\"Training R^2\", reg2.score(X2_train, y2_train))\n",
        "print(\"Test R^2\", reg2.score(X2_test, y2_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df964836",
      "metadata": {
        "id": "df964836"
      },
      "source": [
        "We can see that the accuracy scores are worse, but by using all the variables, the features explained more of the variance compared to cherry picking which variables to use."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7188cc8b",
      "metadata": {
        "id": "7188cc8b"
      },
      "source": [
        "Let's try some more feature combinations using class_weight = 'balanced'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e55093c",
      "metadata": {
        "id": "6e55093c",
        "outputId": "3051ff30-c68e-4020-a1f3-441a6a30b3c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.4069109583079467\n",
            "Test R^2 0.40932822833275323\n"
          ]
        }
      ],
      "source": [
        "# Do more popular songs have the word 'love'?\n",
        "#Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"Popularity Points Awarded\"]]\n",
        "\n",
        "def minmax(z):\n",
        "    z = (z-min(z))/(max(z)-min(z))\n",
        "    return z\n",
        "X = X.apply(minmax,axis=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=100)\n",
        "\n",
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000,\n",
        "                         class_weight='balanced'\n",
        "                         ).fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e9ed448",
      "metadata": {
        "id": "6e9ed448",
        "outputId": "b080e10f-a43d-4661-848f-e465974b88d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.6430498737923231\n",
            "Test R^2 0.6359206404455273\n"
          ]
        }
      ],
      "source": [
        "#Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"liveness\"]]\n",
        "\n",
        "X = X.apply(minmax,axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)\n",
        "\n",
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000,\n",
        "                         class_weight='balanced').fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))\n",
        "# This is the highest accuracy so far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2083176b",
      "metadata": {
        "id": "2083176b",
        "outputId": "a7b24df4-a66d-41f1-b4f4-e7b25ed8d0cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R^2 0.6167638610845156\n",
            "Test R^2 0.608771319178559\n"
          ]
        }
      ],
      "source": [
        "# Trying a mix\n",
        "# Prepare X and y\n",
        "y = song_attribute_data[\"Has Word Love?\"]\n",
        "X = song_attribute_data.loc[:,[\"valence\", \"acousticness\", \"liveness\", \"instrumentalness\"]]\n",
        "\n",
        "X = X.apply(minmax,axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)\n",
        "\n",
        "#Run Regression\n",
        "reg = LogisticRegression(penalty = None,\n",
        "                         fit_intercept=True,\n",
        "                         solver = 'newton-cholesky',\n",
        "                         max_iter=1000,\n",
        "                         class_weight='balanced').fit(X_train,y_train)\n",
        "\n",
        "print(\"Training R^2\" , reg.score(X_train, y_train))\n",
        "print(\"Test R^2\", reg.score(X_test, y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}